# 回测与模拟盘系统使用说明

## 概述

本系统实现了基于OKX BTC-USDT-SWAP的多周期策略回测引擎和模拟盘执行器，支持：

- 事件驱动的15m基准回测
- LLM决策系统集成（支持DeepSeek API和本地Qwen模型）
- 完整的成本模型（手续费、滑点、资金费率）
- 风控约束（杠杆、单笔风险、熔断机制）
- 性能评估和报告生成

**重要更新**：系统现在支持使用本地Qwen模型进行回测，无需API费用，适合大量回测和开发测试。

## 快速开始

### 1. 安装依赖

```bash
pip install -r requirements.txt
```

### 2. 准备数据

**重要：回测系统需要15分钟（15m）数据作为基准周期！**

#### 2.1 下载15分钟历史数据（必需）

```bash
# 下载BTC的15分钟数据（最近365天，推荐）
python update_market_data.py --initial-sync --timeframe 15m --days 365

# 如果只想下载最近180天
python update_market_data.py --initial-sync --timeframe 15m --days 180

# 指定交易对下载
python update_market_data.py --initial-sync --timeframe 15m --symbol BTC/USDT:USDT --days 365
```

**注意事项**：
- 15m数据量较大：365天约35,040根K线（365 × 24 × 4）
- 下载时间：根据网络情况，可能需要几分钟到十几分钟
- 建议至少下载365天数据，以确保技术指标（如EMA200）计算准确

#### 2.2 查看数据统计

```bash
# 确认15m数据已下载
python update_market_data.py --stats
```

这会显示数据库中已有的数据，包括15m数据的时间范围和记录数。

#### 2.3 采集资金费率数据（可选）

```bash
python -c "from src.data.funding_rate_collector import FundingRateCollector; FundingRateCollector().collect_funding_rate_history('BTC-USDT-SWAP', days=90)"
```

#### 2.4 更新最新数据（可选）

```bash
# 只更新最新的15m数据
python update_market_data.py --once --timeframe 15m
```

### 3. 配置回测参数

编辑 `backtest_config.yaml`：

```yaml
instrument:
  instId: "BTC-USDT-SWAP"
  base_symbol: "BTC/USDT:USDT"

backtest:
  start_date: "2024-01-01"
  end_date: "2024-12-31"
  base_timeframe: "15m"

costs:
  maker_fee: 0.0002  # 0.02%
  taker_fee: 0.0005  # 0.05%
  slippage_bps: 5    # 5 bps

risk:
  max_leverage: 5.0
  risk_per_trade: 0.02  # 2% of equity
  daily_loss_limit: 0.05  # 5% daily loss
  max_drawdown_limit: 0.20  # 20% max drawdown

strategy:
  use_llm: true
  llm_strategy: "balanced"  # conservative, balanced, aggressive
  # LLM提供者选项: "deepseek", "local_qwen_ollama", "local_qwen_vllm"
  llm_provider: "local_qwen_ollama"  # 使用本地Qwen模型（推荐用于回测）
  # 本地模型配置（仅当llm_provider为local_qwen_*时有效）
  llm_model_name: "qwen"  # Ollama中的模型名称
  # llm_api_base: "http://localhost:11434"  # 可选，默认使用环境变量或默认地址
```

### 4. 运行回测

```bash
python run_backtest.py --config backtest_config.yaml
```

输出文件：
- `output/backtest/report.txt` - 文本报告
- `output/backtest/report.html` - HTML报告
- `output/backtest/trades.csv` - 交易流水CSV
- `output/backtest/trades.json` - 交易流水JSON

### 5. 启动模拟盘（可选）

```bash
python run_paper_trading.py --config backtest_config.yaml
```

## API使用

### 运行回测

```bash
curl -X POST "http://localhost:8000/api/backtest/run" \
  -H "Content-Type: application/json" \
  -d '{"config_path": "backtest_config.yaml"}'
```

### 查看模拟盘状态

```bash
curl "http://localhost:8000/api/paper_trading/status"
```

### 启动/停止模拟盘

```bash
# 启动
curl -X POST "http://localhost:8000/api/paper_trading/start"

# 停止
curl -X POST "http://localhost:8000/api/paper_trading/stop"
```

## 系统架构

### 核心模块

1. **数据模块** (`src/data/`)
   - `funding_rate_collector.py` - 资金费率采集
   - `fee_config.py` - 手续费配置
   - `bar_aggregator.py` - K线聚合

2. **回测引擎** (`src/backtest/`)
   - `config.py` - 配置系统
   - `engine.py` - 回测引擎核心
   - `account.py` - 虚拟账户
   - `executor.py` - 订单执行
   - `cost_model.py` - 成本模型
   - `risk_manager.py` - 风控管理
   - `performance.py` - 性能评估
   - `trade_log.py` - 交易流水
   - `reporter.py` - 报告生成

3. **模拟盘** (`src/paper_trading/`)
   - `engine.py` - 模拟盘引擎
   - `account_db.py` - 账户持久化

## 关键技术点

### 未来函数避免

- 信号生成时间：`t_close`（15m bar收盘）
- 成交时间：`t_next_open`（下一根K线开盘）
- 数据访问：只能使用 `<= t_current` 的数据

### 成本模型

- **手续费**：`notional * fee_rate` (maker/taker可选)
- **滑点**：Market订单 `next_open +/- slippage_bps`
- **资金费率**：每8小时结算一次

### 风控约束

- 杠杆限制：`abs(position_notional) <= equity * max_leverage`
- 单笔风险：通过 `risk_per_trade` 和 `stop_distance` 反推仓位
- 日内亏损熔断：当日亏损 >= `daily_loss_limit`
- 最大回撤熔断：回撤 >= `max_drawdown_limit`

## 性能指标

回测报告包含以下指标：

- 总收益、年化收益
- 最大回撤
- Sharpe比率
- 胜率、盈亏比
- 手续费总额、资金费率总额、滑点成本
- 交易次数、持仓时间分布

## LLM模型选择

系统支持四种LLM提供者：

### 1. llamafactory直接调用（推荐，最简单）

如果你已经通过llamafactory下载了Qwen模型，可以直接使用这种方式。

**配置**：
```yaml
strategy:
  llm_provider: "llamafactory_qwen"
  llm_model_path: "models/qwen/Qwen2___5-1___5B-Instruct"
  # llm_quantization_bit: 4  # 可选，节省显存
```

**要求**：
- 已安装llamafactory：`pip install llamafactory transformers torch`
- 模型路径正确

**优点**：
- 最简单，无需额外服务
- 直接调用，延迟最低
- 支持量化

**适用场景**：回测、开发测试、已有llamafactory模型

### 2. DeepSeek API（云端）

**配置**：
```yaml
strategy:
  llm_provider: "deepseek"
```

**要求**：
- 需要配置 `DEEPSEEK_API_KEY` 环境变量
- 需要网络连接
- 有API调用费用

**适用场景**：正式上线、需要最新模型能力

### 3. 本地Qwen模型 - Ollama

**配置**：
```yaml
strategy:
  llm_provider: "local_qwen_ollama"
  llm_model_name: "qwen"  # 你的模型名称
  # llm_api_base: "http://localhost:11434"  # 可选
```

**前提条件**：
1. 安装Ollama：访问 https://ollama.ai 下载安装
2. 导入或下载Qwen模型：
   ```bash
   # 方式1：如果已有通过llamafactory下载的模型
   # 需要先转换为Ollama格式（可能需要额外工具）
   
   # 方式2：直接从Ollama下载（推荐，最简单）
   ollama pull qwen
   # 或下载特定版本
   ollama pull qwen:7b
   ollama pull qwen:14b
   ```
3. 验证模型：
   ```bash
   # 查看已安装的模型
   ollama list
   
   # 测试模型是否正常工作
   ollama run qwen "Hello, respond with JSON"
   ```

**优点**：
- 免费，无API费用
- 无速率限制
- 数据隐私
- 适合大量回测

**适用场景**：回测、开发测试、成本敏感场景

### 4. 本地Qwen模型 - VLLM（高性能）

**配置**：
```yaml
strategy:
  llm_provider: "local_qwen_vllm"
  llm_model_name: "qwen"  # 或模型路径
  # llm_api_base: "http://localhost:8000"  # 可选
```

**前提条件**：
1. 安装VLLM：`pip install vllm`
2. 启动VLLM服务：
   ```bash
   python -m vllm.entrypoints.openai.api_server \
       --model /path/to/your/qwen/model \
       --port 8000 \
       --trust-remote-code
   ```

**优点**：
- 性能最优
- 支持并发
- 适合生产环境

**适用场景**：生产环境、需要高性能的场景

## 使用本地Qwen模型进行回测

### 快速开始

1. **安装并配置Ollama**（推荐方式）：
   ```bash
   # 1. 安装Ollama（访问 https://ollama.ai）
   
   # 2. 下载或导入Qwen模型
   ollama pull qwen
   
   # 3. 验证
   ollama list
   ```

2. **配置回测**：
   
   编辑 `backtest_config.yaml`：
   ```yaml
   strategy:
     use_llm: true
     llm_strategy: "balanced"
     llm_provider: "local_qwen_ollama"
     llm_model_name: "qwen"
   ```

3. **运行回测**：
   ```bash
   python run_backtest.py --config backtest_config.yaml
   ```

### Web界面使用

1. 访问 http://localhost:8000/trading
2. 选择"回测"模式
3. 在"LLM模型"下拉菜单中选择"本地Qwen (Ollama)"
4. 在"模型名称"输入框中输入模型名称（默认：qwen）
5. 设置其他回测参数
6. 点击"运行回测"

### 性能对比

| 提供者 | 速度 | 成本 | 稳定性 | 适用场景 |
|--------|------|------|--------|----------|
| DeepSeek API | 快 | 有费用 | 高 | 正式上线 |
| 本地Qwen (Ollama) | 中等 | 免费 | 中等 | 回测、开发 |
| 本地Qwen (VLLM) | 最快 | 免费 | 高 | 生产环境 |

### 使用本地Qwen模型的回测结果特点

#### 1. 结果格式

使用本地Qwen模型进行回测时，生成的结果文件格式与使用DeepSeek API完全一致：

- **性能指标**：总收益、年化收益、最大回撤、Sharpe比率、胜率、盈亏比
- **成本分析**：手续费总额、资金费率总额、滑点成本
- **交易统计**：总交易次数、持仓时间分布、每笔交易详情

#### 2. 性能特点

- **首次调用较慢**：模型首次加载到内存需要时间（通常10-30秒），后续调用会更快
- **回测速度**：取决于模型响应时间和硬件性能
  - CPU模式：每个决策约2-10秒
  - GPU模式：每个决策约0.5-2秒
- **无速率限制**：可以连续进行大量回测，不受API速率限制
- **成本优势**：完全免费，可以无限制回测

#### 3. 结果差异说明

- **模型差异**：Qwen和DeepSeek是不同的模型，决策逻辑可能不同，这是正常的
- **策略一致性**：两种模型都遵循相同的策略框架（conservative/balanced/aggressive）
- **对比分析**：建议同时使用两种模型回测，对比结果，选择表现更好的模型

#### 4. 结果文件示例

回测完成后，查看 `output/backtest/report.txt`：

```
回测结果摘要
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
性能指标
┏━━━━━━━━━━━━━━┳━━━━━━━┓
┃ 指标         ┃ 值    ┃
┡━━━━━━━━━━━━━━╇━━━━━━━┩
│ 总收益       │ 15.30%│
│ 年化收益     │ 18.50%│
│ 最大回撤     │ -8.20%│
│ Sharpe比率   │ 1.45  │
│ 胜率         │ 52.30%│
│ 盈亏比       │ 1.80  │
│ 总交易次数   │ 156   │
│ 手续费总额   │ $125.50│
│ 资金费率总额 │ -$45.20│
└──────────────┴───────┘

使用的模型: 本地Qwen (Ollama) - qwen
回测时间范围: 2024-01-01 到 2024-12-31
策略类型: balanced
```

#### 5. 优化建议

- **硬件优化**：使用GPU可以显著提升回测速度
- **模型选择**：根据硬件选择合适大小的模型（7b/14b/32b）
- **批量回测**：可以同时运行多个回测任务，充分利用硬件资源

### 故障排除

**问题：无法连接到Ollama服务**

错误信息：`无法连接到Ollama服务`

解决：
```bash
# 1. 确保Ollama服务运行
ollama serve

# 2. 检查端口
curl http://localhost:11434/api/tags

# 3. 检查防火墙
```

**问题：模型不存在**

错误信息：`model not found`

解决：
```bash
# 检查模型列表
ollama list

# 如果模型不存在，下载
ollama pull qwen
```

**问题：响应超时**

解决：
- 检查模型大小是否适合硬件
- 考虑使用更小的模型版本（如qwen:7b）
- 增加系统资源

## 注意事项

1. **数据要求**：回测需要至少365天的15m数据，以确保技术指标（如EMA200）计算准确
2. **LLM配置**：
   - 使用DeepSeek API：需要配置 `DEEPSEEK_API_KEY` 环境变量
   - 使用本地Qwen：需要先安装并配置Ollama或VLLM服务
3. **资金费率**：历史资金费率最多获取近3个月的数据
4. **性能**：回测大量数据时可能需要较长时间，建议先用小范围测试
5. **模型选择**：
   - 回测阶段：推荐使用本地Qwen模型，节省成本
   - 正式上线：可以切换到DeepSeek最新模型，获得更好的性能

## 故障排除

### 问题：回测失败，提示没有数据

**解决**：运行15m数据同步
```bash
# 下载15分钟数据（回测系统必需）
python update_market_data.py --initial-sync --timeframe 15m --days 365

# 查看数据是否下载成功
python update_market_data.py --stats
```

### 问题：LLM调用失败

**解决**：检查 `.env` 文件中的 `DEEPSEEK_API_KEY` 配置

### 问题：资金费率获取失败

**解决**：资金费率API可能需要API密钥，或使用默认值（0）

## 回测结果解读

### 使用本地Qwen模型的回测结果

使用本地Qwen模型进行回测时，结果文件包含：

1. **性能指标**：
   - 总收益、年化收益
   - 最大回撤
   - Sharpe比率
   - 胜率、盈亏比

2. **成本分析**：
   - 手续费总额
   - 资金费率总额
   - 滑点成本

3. **交易统计**：
   - 总交易次数
   - 持仓时间分布
   - 每笔交易的详细信息

4. **模型表现**：
   - LLM决策的准确性
   - 策略执行情况
   - 风险控制效果

### 结果文件位置

回测完成后，结果保存在：
```
output/backtest/
├── report.txt          # 文本报告（性能指标）
├── report.html         # HTML报告（可视化）
├── trades.csv          # 交易流水（CSV格式）
└── trades.json         # 交易流水（JSON格式）
```

### 结果分析建议

1. **对比不同模型**：
   - 使用DeepSeek API回测一次
   - 使用本地Qwen回测一次
   - 对比两者的收益、胜率等指标

2. **参数调优**：
   - 调整策略类型（conservative/balanced/aggressive）
   - 调整杠杆上限
   - 调整风险参数

3. **时间范围测试**：
   - 先测试短期（如1个月）
   - 再测试长期（如1年）
   - 观察不同市场环境下的表现

## 下一步

- 添加更多技术指标
- 支持多交易对回测
- 优化回测性能
- 添加可视化图表
- 实现参数优化功能
- 支持模型对比分析
