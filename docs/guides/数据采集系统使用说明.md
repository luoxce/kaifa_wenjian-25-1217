# 市场数据采集系统使用说明

## 📋 概述

这个系统替代了原来的CSV文件方式，通过以下方式管理市场数据：

1. **SQLite数据库存储**：所有OHLCV数据存储在本地SQLite数据库中
2. **实时数据采集**：从OKX交易所获取最新数据
3. **自动定时更新**：每小时自动更新数据
4. **技术分析集成**：技术分析Agent直接从数据库读取数据

---

## 🚀 快速开始

### 第一步：初始同步（获取历史数据）

首次使用需要从交易所获取历史数据：

#### 下载1小时数据（默认）

```bash
# 获取最近365天的历史数据（默认1h）
python update_market_data.py --initial-sync

# 获取最近180天的数据
python update_market_data.py --initial-sync --days 180

# 只同步BTC数据
python update_market_data.py --initial-sync --symbol BTC/USDT:USDT
```

#### 下载15分钟数据（回测系统必需）

**重要**：如果使用回测系统，必须下载15分钟数据！

```bash
# 下载15分钟数据（最近365天，推荐）
python update_market_data.py --initial-sync --timeframe 15m --days 365

# 下载15分钟数据（最近180天）
python update_market_data.py --initial-sync --timeframe 15m --days 180

# 指定交易对下载15分钟数据
python update_market_data.py --initial-sync --timeframe 15m --symbol BTC/USDT:USDT --days 365
```

**注意**：
- 初始同步可能需要几分钟时间，取决于获取的天数
- 建议首次使用获取至少365天的数据，以确保技术指标（如EMA200）计算准确
- **15m数据量较大**：365天约35,040根K线（365 × 24 × 4），下载时间可能较长
- 回测系统使用15m作为基准周期，必须下载15m数据

### 第二步：查看数据库统计

```bash
python update_market_data.py --stats
```

这会显示：
- 数据库文件位置
- 每个交易对的数据量
- 数据的时间范围

### 第三步：手动更新数据

```bash
# 立即更新一次（获取最新1h数据）
python update_market_data.py --once

# 立即更新15m数据（回测系统需要）
python update_market_data.py --once --timeframe 15m
```

### 第四步：启动定时自动更新（可选）

如果需要后台自动更新，可以启动定时任务：

```bash
# 每小时自动更新1h数据（默认）
python update_market_data.py

# 每小时自动更新15m数据（回测系统推荐）
python update_market_data.py --timeframe 15m

# 每30分钟更新一次15m数据
python update_market_data.py --timeframe 15m --interval 1800

# 后台运行（Linux/Mac）
nohup python update_market_data.py --timeframe 15m > update.log 2>&1 &
```

---

## 📊 数据库结构

数据库文件默认位置：`data/market_data.db`

### 表结构

**ohlcv表**：
- `id`: 主键
- `symbol`: 交易对符号（如 "BTC/USDT:USDT"）
- `timeframe`: 时间框架（如 "1h", "4h", "1d"）
- `timestamp`: 时间戳（毫秒）
- `open`: 开盘价
- `high`: 最高价
- `low`: 最低价
- `close`: 收盘价
- `volume`: 成交量
- `created_at`: 记录创建时间

### 索引

- `idx_symbol_timeframe_timestamp`: (symbol, timeframe, timestamp) 唯一索引
- `idx_symbol_timeframe`: (symbol, timeframe) 索引

---

## 🔧 集成到现有系统

### 1. 修改技术分析Agent

技术分析 Agent 当前默认从数据库读取（SQLite：`data/market_data.db`）：

```python
from data.technical_analysis_agent import TechnicalAnalysisAgent

agent = TechnicalAnalysisAgent(
    symbol="BTC/USDT:USDT",
    timeframe="1h",
    limit=500  # 获取最近500根K线
)
report = agent.generate_analysis_report()
```

如需做 CSV 离线实验，可参考 `examples/技术分析Agent示例_csv.py`（数据在 `datasets/`）。

### 2. 在run_decision.py中集成

决策流程中可以将技术分析报告注入 prompt（当前 `run_decision.py` / `api/routes.py` 已内置此逻辑）：

```python
from data.technical_analysis_agent import TechnicalAnalysisAgent

# 创建技术分析Agent
ta_agent = TechnicalAnalysisAgent(
    symbol="BTC/USDT:USDT",
    timeframe="1h",
)
tech_report = ta_agent.generate_analysis_report()

# 将报告注入prompt
prompt = render_prompt(
    account_data,
    market_data,
    positions_data,
    technical_analysis=tech_report,  # 新增技术分析报告
)
```

---

## 📝 命令行参数说明

### update_market_data.py

| 参数 | 说明 | 示例 |
|------|------|------|
| `--initial-sync` | 执行初始同步，获取历史数据 | `--initial-sync` |
| `--timeframe` | 时间框架（1m/5m/15m/30m/1h/4h/12h/1d），默认1h | `--timeframe 15m` |
| `--days` | 初始同步时获取最近多少天的数据 | `--days 365` |
| `--once` | 只执行一次更新 | `--once` |
| `--interval` | 定时任务的更新间隔（秒） | `--interval 3600` |
| `--stats` | 显示数据库统计信息 | `--stats` |
| `--symbol` | 指定交易对进行初始同步 | `--symbol BTC/USDT:USDT` |
| `-v, --verbose` | 显示详细日志 | `-v` |

**常用组合**：
- 下载15m数据（回测必需）：`--initial-sync --timeframe 15m --days 365`
- 更新15m数据：`--once --timeframe 15m`
- 定时更新15m数据：`--timeframe 15m`

---

## 🔄 数据更新机制

### 增量更新

默认情况下，系统使用**增量更新**模式：
- 只获取数据库中不存在的新数据
- 避免重复下载和存储
- 提高更新效率

### 数据去重

- 数据库使用 `(symbol, timeframe, timestamp)` 作为唯一索引
- 如果同一根K线已存在，使用 `INSERT OR REPLACE` 更新
- 确保数据一致性和完整性

---

## 💾 数据管理

### 数据库文件位置

默认位置：`kaifa_wenjian/data/market_data.db`

可以通过环境变量或代码修改：

```python
from src.data.database import MarketDataDB

# 自定义数据库路径
db = MarketDataDB(db_path="/path/to/custom/database.db")
```

### 数据清理

如果需要清理旧数据：

```python
from src.data.database import MarketDataDB

db = MarketDataDB()
# 只保留最近365天的数据
deleted = db.delete_old_data(
    symbol="BTC/USDT:USDT",
    timeframe="1h",
    days_to_keep=365
)
print(f"删除了 {deleted} 条旧记录")
```

---

## ⚙️ 配置说明

### OKX API配置

在 `.env` 文件中配置：

```env
OKX_API_KEY=your_api_key
OKX_API_SECRET=your_api_secret
OKX_PASSWORD=your_passphrase
OKX_HTTP_PROXY=http://127.0.0.1:33210
OKX_HTTPS_PROXY=http://127.0.0.1:33210
OKX_ALL_PROXY=socks5://127.0.0.1:33211
```

**注意**：
- API密钥用于获取私有数据（如账户信息）
- 获取公开市场数据（OHLCV）不需要API密钥，但可能有速率限制
- 建议配置API密钥以获得更好的速率限制

### 交易对配置

在 `src/config.py` 中配置要采集的交易对：

```python
market_symbols: dict[str, str] = {
    "BTC": "BTC/USDT:USDT",
    "ETH": "ETH/USDT:USDT",
    "SOL": "SOL/USDT:USDT",
}
```

---

## 🐛 故障排查

### 问题1：数据库中没有数据

**解决方案**：
```bash
# 执行初始同步
python update_market_data.py --initial-sync
```

### 问题2：API速率限制

**症状**：获取数据时出现速率限制错误

**解决方案**：
1. 配置OKX API密钥（减少速率限制）
2. 增加更新间隔（使用 `--interval` 参数）
3. 减少同时采集的交易对数量

### 问题3：数据更新失败

**症状**：定时任务更新失败

**解决方案**：
1. 检查网络连接和代理设置
2. 查看日志文件了解详细错误
3. 手动执行 `--once` 测试是否能正常获取数据

### 问题4：数据库文件太大

**解决方案**：
1. 定期清理旧数据（使用 `delete_old_data` 方法）
2. 只保留必要的历史数据（例如最近1-2年）
3. 考虑使用SQLite的VACUUM命令压缩数据库

---

## 📈 性能优化

### 1. 数据库索引

数据库已自动创建必要的索引，无需手动优化。

### 2. 批量插入

数据采集使用批量插入，提高写入性能。

### 3. 增量更新

默认使用增量更新，只获取新数据，减少API调用。

---

## 🔐 安全建议

1. **API密钥安全**：
   - 不要将API密钥提交到版本控制
   - 使用 `.env` 文件存储（已在 `.gitignore` 中）
   - 定期轮换API密钥

2. **数据库备份**：
   - 定期备份 `data/market_data.db` 文件
   - 可以使用SQLite的备份命令：
     ```bash
     sqlite3 data/market_data.db ".backup backup.db"
     ```

3. **权限控制**：
   - 数据库文件应该有适当的文件权限
   - 不要在公共目录存储数据库文件

---

## 📚 API参考

### MarketDataDB

数据库管理类，提供数据存储和查询功能。

#### 主要方法

- `insert_candles()`: 插入K线数据
- `get_candles()`: 获取K线数据
- `get_latest_timestamp()`: 获取最新时间戳
- `get_data_stats()`: 获取统计信息
- `delete_old_data()`: 删除旧数据

### MarketDataCollector

数据采集类，从交易所获取数据。

#### 主要方法

- `collect_candles()`: 采集指定交易对的K线数据
- `collect_all_symbols()`: 采集所有配置的交易对
- `initial_sync()`: 初始同步历史数据

### TechnicalAnalysisAgent

技术分析Agent，从数据库读取数据进行分析。

#### 主要方法

- `load_data()`: 从数据库加载数据
- `calculate_indicators()`: 计算技术指标
- `analyze_trend()`: 分析趋势
- `generate_analysis_report()`: 生成分析报告

---

## 🎯 下一步

1. ✅ **已完成**：数据库存储、数据采集、定时更新
2. 🔄 **待集成**：将数据库版本的技术分析Agent集成到决策流程中
3. 🔄 **待优化**：根据实际使用情况调整更新频率和数据保留策略
4. 🔄 **可选**：添加更多时间框架（4h、1d等）的数据采集

---

## 💡 常见问题

### Q: 数据库文件会不断增大吗？

A: 是的，但随着时间增长，增长速率会变慢（每小时只增加少量新数据）。可以定期清理旧数据。

### Q: 可以同时使用CSV和数据库吗？

A: 可以，但建议逐步迁移到数据库方式。数据库方式更灵活、更可靠。

### Q: 数据采集会影响交易决策吗？

A: 不会。数据采集是独立的，可以后台运行。技术分析Agent读取数据是只读操作，性能很高。

### Q: 如何迁移CSV数据到数据库？

A: 可以编写脚本读取CSV并导入数据库，或者直接使用初始同步获取历史数据。

---

**如有问题，请查看日志文件或使用 `--verbose` 参数获取详细错误信息。**



